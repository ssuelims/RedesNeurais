{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação de Redes Neurais - Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mapa mental de redes neurais\n",
    "- https://www.mindmeister.com/3493965223/deep-learning-aprendizado-profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pela lei brasileira e segurança no trânsito é proibido dirigir com sonolência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementar uma inteligência artificial \n",
    "- Criar um projeto de aplicação de redes neurais - Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As tecnologias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linguagem de Programação Python\n",
    "- Biblioteca OpenCV\n",
    "- Media Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equipamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Camera 0 ou Camera 1 ou Outra Cameras\n",
    "- Camera Escolhida Logitech N231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicando as Tecnologias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A biblioteca MediaPipe - para fazer o reconhecimento da face \n",
    "- A biblioteca OpenCV - para tratar os dados visuais\n",
    "- A biblioteca NumPy - para cálculos matemáticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from opencv-python) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze >> requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (0.4.35)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (0.4.35)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (2.1.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.4.0 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from jax->mediapipe) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ead\\documents\\sueli\\redesneurais\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O projeto é ponto de partida (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ideias inovadoras (InovaTech)\n",
    "- Implementar e sugerir novas idéias para a Industria Automobística (SENAI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 00000297FE6F2550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- se você tiver mais camêras, precisa colocar o número correspondente a elas. \n",
    "- agora, vamos armazenar a saída dessa captura a uma variável que chamaremos de cap (referente a \"captura\")\n",
    "- ao utilizar a camera se atentar que as vezes temos mais de uma camera no computador, por exemplo, uma você usa para fazer uma videoconferência e a outra gravar um tela.\n",
    "- Se for apenas uma camera utilizar o valor 0\n",
    "- Se tem mais de uma colocar o número correspondente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- você lembra do while ?\n",
    "- vamos revisar?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# o while é uma estrutura de repetição (iteração) , chamada também de looping\n",
    "cont = 1\n",
    "while cont<=10:\n",
    "    print(cont)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usando o while, receberemos a primeira captura (inicio) \n",
    "- O objetivo é que a captura aconteça ao vivo\n",
    "- Para isso, devemos adicionar uma estrutura de repetição\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos agora aplicar o while, no nosso projeto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Códigos essenciais\n",
    "\n",
    "# while cap.isOpened() - enquanto a camera estiver aberta o while continuara rodando\n",
    "while cap.isOpened():\n",
    "    # vamos criar duas variáveis\n",
    "    \n",
    "    # SUCESSO verifica se os dados estão sendo coletados.\n",
    "            #  Ela é booleana, significa que se identificar algum vídeo ou frame, retornará verdadeiro. Se não identificar nenhum vídeo, retornará falso\n",
    "    # FRAME é uma variável frame que por sua vez, é a captura coletada pela câmera. \n",
    "\n",
    "    sucesso,frame = cap.read()  # Utilizaremos o método cap.read() para leitura\n",
    "    # agora vamos usar o if (condicional), vamos verificar se existe ou não captura acontecendo\n",
    "    # se não tivermos sucesso (booleano), queremos uma mensagem na tela - ignorando o frame vazio da camêra\n",
    "    # essa mensagem é um aviso, logo , nada esta acontecendo no nosso projeto\n",
    "    if not sucesso:\n",
    "        print('Ignorando o frame vazio da camêra')\n",
    "        continue # pesquise sobre a diferença do continue e break (história go to)\n",
    "    # depois disso, saímos do bloco condicional e podemos visualizar a captura e conferir o que está acontecendo.\n",
    "    # podemos contar com o método imshow( ) pra isso\n",
    "    # dentro dos parenteses passamos dois parâmetros 'Camera' e frame\n",
    "    # Passaremos um nome para nossa janela no formato string 'Camera'\n",
    "    # Também outro parametro - frame - definindo que o que queremos mostrar que é nosso próprio frame\n",
    "    cv2.imshow('Camera',frame)\n",
    "    # com isso, conseguiremos mostrar a imagem, mas não temos uma opção de controle para fechar a camera em tempo real.\n",
    "    # Para isso, usaremos um condicional if\n",
    "    # Ele vai pegar o laço de repetição quando apertarmos teclas específicas.\n",
    "    # Como a intenção é fechar vamos usar \"C\" de \"Close\"\n",
    "    # waitKey(10) vai esperar uma chave\n",
    "    # verificar se essa chave é c\n",
    "    # Para isso passamos & OxFF \n",
    "    \"\"\"\n",
    "      Detalhando mais\n",
    "\n",
    "      cv2.waitKey(10)\n",
    "\n",
    "            cv2.waitKey() é uma função do OpenCV\n",
    "            Que espera por uma entrada de tecla por um certo período de tempo em milissegundos\n",
    "            Passado como argumento. \n",
    "            Nesse caso, 10 indica que o programa espera 10 milissegundos.\n",
    "            Se uma tecla for pressionada durante esse tempo o código da tecla será retornado.\n",
    "            Se nenhum valor for passado, o waitKey() não bloqueia a execução e retorna -1 se nenhuma tecla for pressionada\n",
    "    \n",
    "      & 0xFF\n",
    "\n",
    "            O operador & 0xFF é uma operação de bitwise AND com 0xFF (255 em hexadecimal).\n",
    "            Isso é feito para garantir compatibilidade com sistemas operacionais diferentes.\n",
    "            Isolando o último byte do código da tecla pressionada. \n",
    "            Muitas vezes, sistemas operacionais retornam um valor de 32 bits.\n",
    "            Mas 0xFF restringe o valor à faixa de 0 a 255, que é a faixa da tabela ASCII.    \n",
    "    \n",
    "      == ord('c')\n",
    "\n",
    "           ord('c') retorna o código ASCII do caractere 'c', que é 99.\n",
    "           Esse trecho está verificando se a tecla pressionada foi 'c'. \n",
    "           Se for, a condição do if será verdadeira, permitindo que um bloco de código seja \n",
    "           executado a seguir.\n",
    "    \"\"\"\n",
    "    if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "        break\n",
    "# agora para fechar a caputura fora do if e do while\n",
    "cap.release()\n",
    "# também, vamos fechar todas as janelas/pop-ups, pois o método imshow() vai abrir um pop-up, mostrando um frame\n",
    "cv2.destroyAllWindows()\n",
    "# agora é só conectar a camera e executar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 2 - MediaPipe Face Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe' has no attribute 'solution'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# primeiro vamos importar o mediapipe\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mp_drawing \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolution\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mediapipe' has no attribute 'solution'"
     ]
    }
   ],
   "source": [
    "# importando mp\n",
    "import mediapipe as mp\n",
    "# primeiro vamos importar o mediapipe\n",
    "mp_drawing = mp.solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
